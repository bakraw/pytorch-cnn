############################## IMPORTS ##############################


import torch
import torchvision


############################## MOD√àLE ##############################


# CNN basique, avec 3 convolutions et 2 fully connected layers.
class Cnn(torch.nn.Module):
    def __init__(self):
        super().__init__()

        # Max pooling 2x2, qu'on appliquera apr√®s chaque convolution.
        # Concr√®tement, la taille des images sera divis√©e par 2, ce qui permettra de mieux r√©sister aux l√©g√®res diff√©rences.
        self.pool = torch.nn.MaxPool2d(2, 2)

        # Convolutions
        # On se retrouvera avec une feature map de 4x4x64
        self.conv1 = torch.nn.Conv2d(3, 32, 3) # 3 inputs (RGB), 32 outputs, kernels 3x3
        self.conv2 = torch.nn.Conv2d(32, 64, 3) # 32 inputs, 64 outputs, kernels 3x3
        self.conv3 = torch.nn.Conv2d(64, 64, 3) # 64 inputs, 64 outputs, kernels 3x3

        # Fully connected layers
        # On passera de notre feature map √† nos 10 classes
        self.fc1 = torch.nn.Linear(64 * 4 * 4, 64) # 1024 inputs, 64 outputs
        self.fc2 = torch.nn.Linear(64, 10) # 64 inputs, 10 outputs

    def forward(self, x):
        # Matrice initiale: 32x32x3
        x = torch.nn.functional.relu(self.conv1(x)) # -> 30x30x32 (ReLU passe les valeurs n√©gatives √† 0)
        x = self.pool(x) # -> 15x15x32
        x = torch.nn.functional.relu(self.conv2(x)) # -> 13x13x64
        x = self.pool(x) # -> 6x6x64
        x = torch.nn.functional.relu(self.conv3(x)) # -> 4x4x64
        x = torch.flatten(x, 1) # -> 1024x1 (n√©cessaire pour les FCL qui attendent un vecteur en entr√©e)
        x = torch.nn.functional.relu(self.fc1(x)) # -> 64x1
        x = self.fc2(x) # -> 10x1
        return x


################################### ENTRA√éNEMENT ##############################


# On utilise CUDA si disponible, le CPU sinon.
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("\033[92m‚úì CUDA actif.\033[0m" if device.type == 'cuda' else "\033[91m‚ö† CUDA indisponible. Ex√©cution sur le CPU.\033[0m")

# Hyperparam√®tres
EPOCHS = 10 # Nombre d'it√©rations pour l'entra√Ænement.
            # Plus grand -> plus pr√©cis.
            # Plus petit -> plus rapide, moins de risque d'overfitting.

LEARNING_RATE = 0.001 # Vitesse d'apprentissage ("taille des pas").
                      # Plus grand -> plus rapide, sort des minima locaux plus facilement.
                      # Plus petit -> plus pr√©cis.

BATCH_SIZE = 32 # Nombres d'images trait√©es √† chaque it√©ration.
                # Plus grand -> plus rapide, calcul de gradient plus "stable".
                # Plus petit -> moins de risque de blocage dans un minimum local, moins de m√©moire utilis√©e.

# Transformations √† appliquer aux images.
# On a (x - mean) / std tel que pour x = 0, on a (0 - 0,5) / 0,5 = -1 et pour x = 1 (initialement 255), on a (1 - 0,5) / 0,5 = 1.
transform = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor(),  # Transforme les images en tenseurs Pytorch (et transforme les valeurs de 0 √† 255 en valeurs entre 0 et 1)
    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Transforme les valeurs de 0 √† 1 en valeurs entre -1 et 1
    ])

# Import de CIFAR10 (60000 images de 32x32, 10 classes)
training_dataset = torchvision.datasets.CIFAR10('./data', True, transform, None, True)
testing_dataset = torchvision.datasets.CIFAR10('./data', True, transform, None, True)

# Cr√©ation des DataLoaders
training_loader = torch.utils.data.DataLoader(training_dataset, BATCH_SIZE, True)
testing_loader = torch.utils.data.DataLoader(testing_dataset, BATCH_SIZE, True)

# D√©finition des classes
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# Instantiation du mod√®le
model = Cnn().to(device)

# Fonction de perte, qui calcule l'√©cart entre la sortie du mod√®le et la sortie attendue.
# La cross-entropy punit plus s√©v√®rement les erreurs qui ont un haut taux de certitude.
loss_function = torch.nn.CrossEntropyLoss() 

# Optimiseur, qui va modifier les param√®tres du mod√®le pour minimiser la fonction de perte.
# Le Adam peut ajuster la taille des pas en m√©morisant les modifs pr√©c√©dentes, en et affectant plus les param√®tres qui changent rarement.
# Il est donc plus efficace que le SGD, qui se contente d'avancer vers le minimum global selon une taille de pas fixe.
optimizer = torch.optim.Adam(model.parameters(), LEARNING_RATE)

# Entra√Ænement
print("\033[93müõà D√©but de l'entra√Ænement...\033[0m")
total_steps = len(training_loader) # On s'en servira pour calculer la perte moyenne par batch.
for epoch in range(EPOCHS): 
    total_loss = 0.0

    # On parcourt les batches
    for i, (images, labels) in enumerate(training_loader):
        # Passage sur le GPU si disponible
        images = images.to(device)
        labels = labels.to(device)

        # Forward pass
        outputs = model(images) # On passe les images au mod√®le pour obtenir les pr√©dictions
        loss = loss_function(outputs, labels) # On calcule la perte entre les pr√©dictions et les labels r√©els

        # Backward pass
        loss.backward() # Backpropagation ; on transmet les gradients calcul√©s par la fonction de perte.
                        # Les gradients repr√©sentent la d√©riv√©e de la fonction de perte par rapport aux param√®tres du mod√®le.
                        # Chaque param√®tre aura un gradient associ√©, qui indiquera √† l'optimiseur comment modifier le param√®tre pour r√©duire la perte.

        # Ajustement des param√®tres
        optimizer.step() # On ajuste les param√®tres du mod√®le en fonction des gradients calcul√©s.
        optimizer.zero_grad() # On r√©initialise les gradients pour le batch suivant.
        total_loss += loss.item() # On ajoute la perte du batch √† la perte totale.

    print(f'Epoch: {epoch + 1}/{EPOCHS}, Perte: {total_loss / total_steps:.4f}')

print("\033[92m‚úì Entra√Ænement termin√©.\033[0m")

# Sauvegarde du mod√®le
print("\033[93müõà Sauvegarde du mod√®le...\033[0m")
torch.save(model.state_dict(), 'model.pth')
print("\033[92m‚úì Mod√®le sauvegard√©.\033[0m")



################################### TEST ##############################

print("\033[93müõà D√©but du test...\033[0m")
model.eval() # On met le mod√®le en mode √©valuation.

with torch.no_grad(): # On d√©sactive le calcul des gradients pour acc√©l√©rer les calculs.
    correct = 0
    samples = len(testing_loader.dataset)

    for images, labels in testing_loader:
        # Passage sur le GPU si disponible
        images = images.to(device)
        labels = labels.to(device)

        # Pr√©dictions
        outputs = model(images) 
        _, predicted = torch.max(outputs.data, 1) # On prend la classe avec la plus grande probabilit√©.
        correct += (predicted == labels).sum().item()

print("\033[92m‚úì Test termin√©.\033[0m")
print(f'Pr√©cision: {100 * correct / samples:.2f}%')

